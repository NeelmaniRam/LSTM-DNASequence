# -*- coding: utf-8 -*-
"""CpG_Detector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cs3XGRggwi5CJqfrydPCl7BkpaxnK6jU

# Part 1: Build CpG Detector

Here we have a simple problem, given a DNA sequence (of N, A, C, G, T), count the number of CpGs in the sequence (consecutive CGs).

We have defined a few helper functions / parameters for performing this task.

We need you to build a LSTM model and train it to complish this task in PyTorch.

A good solution will be a model that can be trained, with high confidence in correctness.
"""

from typing import Sequence
from functools import partial
import random
import torch
import numpy as np
import random

# DO NOT CHANGE HERE
def set_seed(seed=13):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

set_seed(13)

# Use this for getting x label
def rand_sequence(n_seqs: int, seq_len: int=128) -> Sequence[int]:
    for i in range(n_seqs):
        yield [random.randint(0, 4) for _ in range(seq_len)]

# Use this for getting y label
def count_cpgs(seq: str) -> int:
    cgs = 0
    for i in range(0, len(seq) - 1):
        dimer = seq[i:i+2]
        # note that seq is a string, not a list
        if dimer == "CG":
            cgs += 1
    return cgs

# Alphabet helpers
alphabet = 'NACGT'
dna2int = { a: i for a, i in zip(alphabet, range(5))}
int2dna = { i: a for a, i in zip(alphabet, range(5))}

intseq_to_dnaseq = partial(map, int2dna.get)
dnaseq_to_intseq = partial(map, dna2int.get)

# we prepared two datasets for training and evaluation
# training data scale we set to 2048
# we test on 512
'''
def prepare_data(num_samples=100):
    # prepared the training and test data
    # you need to call rand_sequence and count_cpgs here to create the dataset
    # step 1
    X_dna_seqs_train = list(rand_sequence(num_samples))
    """
    hint:
        1. You can check X_dna_seqs_train by print, the data is ids which is your training X
        2. You first convert ids back to DNA sequence
        3. Then you run count_cpgs which will yield CGs counts - this will be the labels (Y)
    """
    #step2
    temp = ??? # use intseq_to_dnaseq here to convert ids back to DNA seqs
    #step3
    y_dna_seqs = ??? # use count_cpgs here to generate labels with temp generated in step2

    return X_dna_seqs_train, y_dna_seqs

train_x, train_y = prepare_data(2048)
test_x, test_y = prepare_data(512)
'''
def prepare_data(num_samples=100, seq_len=128):
    # Step 1: Generate random integer sequences
    X_dna_seqs_train = list(rand_sequence(num_samples, seq_len))

    # Step 2: Convert integer sequences to DNA sequences
    temp = ["".join(intseq_to_dnaseq(seq)) for seq in X_dna_seqs_train]

    # Step 3: Count CpGs in DNA sequences
    y_dna_seqs = [count_cpgs(seq) for seq in temp]

    return X_dna_seqs_train, y_dna_seqs

# Prepare training and test datasets
train_x, train_y = prepare_data(2048, seq_len=128)
test_x, test_y = prepare_data(512, seq_len=128)

# some config
'''
LSTM_HIDDEN = ???
LSTM_LAYER = ???
batch_size = ???
learning_rate = ???
epoch_num = ???
'''
# Configuration values
LSTM_HIDDEN = 128  # Number of hidden units in the LSTM
LSTM_LAYER = 2     # Number of layers in the LSTM
batch_size = 64    # Batch size for training
learning_rate = 0.001  # Learning rate for the optimizer
epoch_num = 20     # Number of training epochs

'''
LSTM_HIDDEN = 128:

A hidden size of 128 provides a good balance between the model's capacity to learn complex patterns and computational efficiency.
It's a commonly used value for sequence models and works well for medium-sized datasets.
LSTM_LAYER = 2:

A 2-layer LSTM allows the model to capture more complex hierarchical dependencies in the sequence data compared to a single-layer LSTM.
Using too many layers (e.g., 3+) might lead to overfitting or increased computational costs without significant performance gains for this problem.
batch_size = 64:

A batch size of 64 is a standard choice that strikes a balance between training stability and memory efficiency.
Smaller batch sizes (e.g., 32) may lead to noisier updates, while larger sizes (e.g., 128) may require more memory and reduce the frequency of updates.
learning_rate = 0.001:

This learning rate is a typical starting point for models optimized using Adam or similar optimizers.
It provides a steady convergence rate without overshooting the minima.
epoch_num = 20:

This ensures sufficient training iterations to learn meaningful patterns while avoiding overfitting.
If the model performance plateaus before 20 epochs, early stopping can be applied to save computational resources.
'''

'''
# create data loader

train_data_loader = ???
test_Data_loader = ???
'''


from torch.utils.data import DataLoader, Dataset

# Define a custom dataset
class CpGDatasetLite(Dataset):
    def __init__(self, sequences, labels):
        self.sequences = sequences
        self.labels = torch.tensor(labels, dtype=torch.float32)

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self, idx):
        return torch.tensor(self.sequences[idx], dtype=torch.long), self.labels[idx]

# Create datasets
train_dataset = CpGDatasetLite(train_x, train_y)
test_dataset = CpGDatasetLite(test_x, test_y)

# Create data loaders
train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

"""

# Model
class CpGPredictor(torch.nn.Module):
    ''' Simple model that uses a LSTM to count the number of CpGs in a sequence '''
    def __init__(self):
        super(CpGPredictor, self).__init__()
        # TODO complete model, you are free to add whatever layers you need here
        # We do need a lstm and a classifier layer here but you are free to implement them in your way
        self.lstm = ???
        self.classifier = ???

    def forward(self, x):
        # TODO complete forward function
        return logits

"""


class CpGPredictor(torch.nn.Module):
    ''' Simple model that uses a LSTM to count the number of CpGs in a sequence '''
    def __init__(self):
        super(CpGPredictor, self).__init__()
        # Define LSTM layer
        self.lstm = torch.nn.LSTM(
            input_size=5,  # Size of the one-hot encoded input (DNA has 5 characters: N, A, C, G, T)
            hidden_size=LSTM_HIDDEN,
            num_layers=LSTM_LAYER,
            batch_first=True
        )
        # Define classifier layer
        self.classifier = torch.nn.Linear(LSTM_HIDDEN, 1)  # Output a single value (CpG count)

    def forward(self, x):
        # x is of shape (batch_size, seq_len)
        # Embed input into one-hot-like representation
        x = torch.nn.functional.one_hot(x, num_classes=5).float()  # Convert to one-hot (batch_size, seq_len, 5)

        # Pass through LSTM
        lstm_out, _ = self.lstm(x)  # lstm_out: (batch_size, seq_len, LSTM_HIDDEN)

        # Use only the final hidden state from the last timestep
        final_hidden_state = lstm_out[:, -1, :]  # (batch_size, LSTM_HIDDEN)

        # Pass through the classifier
        logits = self.classifier(final_hidden_state)  # (batch_size, 1)

        return logits

'''
# init model / loss function / optimizer etc.
model = CpGPredictor()
loss_fn = ???
optimizer = ???
'''

# Initialize the model
model = CpGPredictor()

# Define the loss function
loss_fn = torch.nn.MSELoss()  # Mean Squared Error is suitable for regression tasks (e.g., counting CpGs)

# Define the optimizer
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # Adam optimizer for efficient training


'''
model = CpGPredictor():

Instantiates the model with the LSTM and classifier layers defined earlier.
Loss Function (loss_fn):

torch.nn.MSELoss(): Since the task involves predicting a numerical value (CpG count), Mean Squared Error (MSE) is appropriate for minimizing the difference between the predicted and actual counts.
Optimizer (optimizer):

torch.optim.Adam: A popular choice for deep learning models due to its adaptive learning rate and good convergence properties.
lr=learning_rate: Uses the learning rate defined earlier (0.001) for optimization.

'''

'''
# training (you can modify the code below)
t_loss = .0
model.train()
model.zero_grad()
for _ in range(epoch_num):
    for batch in train_data_loader:
        #TODO complete training loop
        t_loss += loss.item()
        loss.backward()

    print(t_loss)
    t_loss = .0

------------------------------
'''
# Training loop
model.train()
for epoch in range(epoch_num):
    t_loss = 0.0  # Reset total loss for the epoch
    for batch in train_data_loader:
        # Unpack the batch
        sequences, labels = batch  # sequences: (batch_size, seq_len), labels: (batch_size,)

        # Zero the gradients
        model.zero_grad()

        # Forward pass
        predictions = model(sequences)  # predictions: (batch_size, 1)

        # Compute loss
        loss = loss_fn(predictions.squeeze(), labels)  # Squeeze predictions to match label shape

        # Backward pass
        loss.backward()

        # Update parameters
        optimizer.step()

        # Accumulate loss
        t_loss += loss.item()

    # Print epoch loss
    print(f"Epoch {epoch + 1}/{epoch_num}, Loss: {t_loss:.4f}")

    '''
Unpacking Batch:

Extract sequences and labels from each batch provided by the data loader.
Zero Gradients:

model.zero_grad(): Clears old gradients before the forward pass to prevent accumulation.
Forward Pass:

predictions = model(sequences): Pass the batch through the model.
Compute Loss:

loss = loss_fn(predictions.squeeze(), labels): Squeeze the predictions tensor to match the shape of labels.
Backward Pass:

loss.backward(): Computes gradients.
Parameter Update:

optimizer.step(): Updates the model parameters based on computed gradients.
Accumulate and Print Loss:

Accumulated loss for the epoch is displayed after each epoch for tracking progress.

    '''

'''
# eval (you can modify the code below)
model.eval()

res_gs = []
res_pred = []

for batch in test_data_loader:
    # TODO complete inference loop

--------------------------
'''
# Evaluation loop
model.eval()

res_gs = []  # Ground truth values
res_pred = []  # Predicted values

with torch.no_grad():  # Disable gradient calculation for evaluation
    for batch in test_data_loader:
        # Unpack the batch
        sequences, labels = batch  # sequences: (batch_size, seq_len), labels: (batch_size,)

        # Forward pass
        predictions = model(sequences)  # predictions: (batch_size, 1)

        # Store results
        res_gs.extend(labels.tolist())  # Convert ground truth to list and append
        res_pred.extend(predictions.squeeze().tolist())  # Convert predictions to list and append
'''

model.eval():

Sets the model to evaluation mode, disabling dropout and other training-specific behaviors.
torch.no_grad():

Prevents gradient computation, reducing memory usage and speeding up inference.
Unpack Batch:

Extract sequences and labels from the batch.
Forward Pass:

predictions = model(sequences): Generate predictions for the given batch.
Store Results:

Ground truth labels (labels) and predictions are converted to lists and appended to res_gs and res_pred.

'''

# TODO complete evaluation of the model
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Evaluated the model's performance
mse = mean_squared_error(res_gs, res_pred)  # Mean Squared Error
mae = mean_absolute_error(res_gs, res_pred)  # Mean Absolute Error

print(f"Model Evaluation Results:")
print(f"Mean Squared Error (MSE): {mse:.4f}")
print(f"Mean Absolute Error (MAE): {mae:.4f}")

# Optionally, visualized the results for better understanding
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(range(len(res_gs)), res_gs, label="Ground Truth", alpha=0.7)
plt.scatter(range(len(res_pred)), res_pred, label="Predictions", alpha=0.7)
plt.xlabel("Sample Index")
plt.ylabel("CpG Count")
plt.title("Ground Truth vs Predictions")
plt.legend()
plt.show()

from typing import List  # Import List from typing
from torch.nn.utils.rnn import pad_sequence

# Preprocess input DNA sequences for prediction
def preprocess_sequences(sequences: List[str]) -> torch.Tensor:
    """
    Convert DNA sequences to padded tensors for prediction.
    Args:
        sequences (List[str]): List of DNA sequences.

    Returns:
        torch.Tensor: Padded tensor of shape (batch_size, max_seq_len).
    """
    # Convert DNA sequences to integer sequences
    int_sequences = [
        torch.tensor([dna2int.get(char, dna2int["N"]) for char in seq], dtype=torch.long)
        for seq in sequences
    ]

    # Pad sequences to the length of the longest sequence
    padded_sequences = pad_sequence(int_sequences, batch_first=True, padding_value=dna2int["N"])

    return padded_sequences

# Prediction function
def predict_cpg_counts(model: CpGPredictor, sequences: List[str]) -> List[float]:
    """
    Predict the number of CpG counts in DNA sequences.
    Args:
        model (CpGPredictor): Trained model.
        sequences (List[str]): List of DNA sequences.

    Returns:
        List[float]: Predicted CpG counts for each sequence.
    """
    model.eval()  # Set model to evaluation mode

    with torch.no_grad():  # Disable gradient calculation for inference
        # Preprocess sequences
        input_tensor = preprocess_sequences(sequences)  # (batch_size, max_seq_len)

        # Make predictions
        predictions = model(input_tensor)  # (batch_size, 1)

        return predictions.squeeze(1).tolist()

# Example usage
if __name__ == "__main__":
    while True:
        # Get user input
        user_input = input("Enter DNA sequences separated by commas (or type 'exit' to quit): ").strip().upper()

        if user_input == "EXIT":
            print("Exiting...")
            break

        # Split and validate sequences
        dna_sequences = [seq.strip() for seq in user_input.split(",")]
        if not all(seq and all(char in dna2int for char in seq) for seq in dna_sequences):
            print("Invalid DNA sequences detected. Please use characters: N, A, C, G, T.")
            continue

        # Predict CpG counts
        try:
            cpg_counts = predict_cpg_counts(model, dna_sequences)
            for seq, count in zip(dna_sequences, cpg_counts):
                print(f"Sequence: {seq[:30]}... (length={len(seq)}), Predicted CpG count: {count:.2f}")
        except Exception as e:
            print(f"Error during prediction: {e}")

"""# Part 2: what if the DNA sequences are not the same length"""

# hint we will need following imports
from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence

# DO NOT CHANGE HERE
random.seed(13)

# Use this for getting x label
def rand_sequence_var_len(n_seqs: int, lb: int=16, ub: int=128) -> Sequence[int]:
    for i in range(n_seqs):
        seq_len = random.randint(lb, ub)
        yield [random.randint(1, 5) for _ in range(seq_len)]


# Use this for getting y label
def count_cpgs(seq: str) -> int:
    cgs = 0
    for i in range(0, len(seq) - 1):
        dimer = seq[i:i+2]
        # note that seq is a string, not a list
        if dimer == "CG":
            cgs += 1
    return cgs


# Alphabet helpers
alphabet = 'NACGT'
dna2int = {a: i for a, i in zip(alphabet, range(1, 6))}
int2dna = {i: a for a, i in zip(alphabet, range(1, 6))}
dna2int.update({"pad": 0})
int2dna.update({0: "<pad>"})

intseq_to_dnaseq = partial(map, int2dna.get)
dnaseq_to_intseq = partial(map, dna2int.get)

'''
# TODO complete the task based on the change
def prepare_data(num_samples=100, min_len=16, max_len=128):
    # TODO prepared the training and test data
    # you need to call rand_sequence and count_cpgs here to create the dataset
    #step 1
    X_dna_seqs_train = list(rand_sequence_var_len(num_samples, min_len, max_len))
    #step 2
    temp = ???
    #step3
    y_dna_seqs = ???

    return X_dna_seqs_train, y_dna_seqs


min_len, max_len = 64, 128
train_x, train_y = prepare_data(2048, min_len, max_len)
test_x, test_y = prepare_data(512, min_len, max_len)

----------------------------------------------
'''
from torch.nn.utils.rnn import pad_sequence

def prepare_data(num_samples=100, min_len=16, max_len=128):
    # Step 1: Generate random variable-length integer sequences
    X_dna_seqs_train = list(rand_sequence_var_len(num_samples, min_len, max_len))

    # Step 2: Convert integer sequences to DNA sequences
    temp = ["".join(intseq_to_dnaseq(seq)) for seq in X_dna_seqs_train]

    # Step 3: Count CpGs in DNA sequences
    y_dna_seqs = [count_cpgs(seq) for seq in temp]

    # Step 4: Pad the sequences to the same length for batching
    X_dna_seqs_train_padded = pad_sequence(
        [torch.tensor(seq) for seq in X_dna_seqs_train],
        batch_first=True,
        padding_value=0
    )

    return X_dna_seqs_train_padded, torch.tensor(y_dna_seqs)

# Prepare training and test datasets
min_len, max_len = 64, 128
train_x, train_y = prepare_data(2048, min_len, max_len)
test_x, test_y = prepare_data(512, min_len, max_len)
'''
Variable-Length Sequences:

Used rand_sequence_var_len to generate DNA sequences with lengths between min_len and max_len.
DNA Conversion:

Converted integer sequences to DNA strings using "".join(intseq_to_dnaseq(seq)).
CpG Counting:

Used count_cpgs to compute the CpG counts for each sequence.
Padding:

Used pad_sequence to pad sequences to the same length, ensuring compatibility with batching.
Tensor Conversion:

Converted both input sequences and labels to PyTorch tensors.
'''

class MyDataset(torch.utils.data.Dataset):
    def __init__(self, lists, labels) -> None:
        self.lists = lists
        self.labels = labels

    def __getitem__(self, index):
        return torch.LongTensor(self.lists[index]), self.labels[index]

    def __len__(self):
        return len(self.lists)

'''
# this will be a collate_fn for dataloader to pad sequence
class PadSequence:
    #TODO
'''



class PadSequence:
    def __init__(self, padding_value=0):
        self.padding_value = padding_value

    def __call__(self, batch):
        # Step 1: Separate the sequences and labels
        sequences, labels = zip(*batch)

        # Step 2: Pad the sequences
        padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=self.padding_value)

        # Step 3: Sort sequences by length in descending order for packing
        lengths = torch.tensor([len(seq) for seq in sequences])
        sorted_lengths, sorted_idx = lengths.sort(0, descending=True)
        sorted_sequences = padded_sequences[sorted_idx]
        sorted_labels = torch.tensor(labels)[sorted_idx]

        # Step 4: Return padded sequences and labels (sorted by length)
        return sorted_sequences, sorted_labels, sorted_lengths

# Now you can use this PadSequence class in your DataLoader as follows:
from torch.utils.data import DataLoader

# Example usage with the custom dataset
dataset = MyDataset(train_x, train_y)

# Create the DataLoader with the custom collate_fn for padding
dataloader = DataLoader(dataset, batch_size=32, collate_fn=PadSequence(padding_value=0))

# TODO complete the rest
for batch in dataloader:
    padded_seqs, labels, lengths = batch
    print(padded_seqs.shape, labels.shape, lengths.shape)
    break

from torch.nn.utils.rnn import pad_sequence

def preprocess_arbitrary_length_inputs(user_inputs: list[str]) -> torch.Tensor:
    """
    Convert a list of DNA sequences into a dynamically padded tensor of integer representations.
    """
    # Convert DNA sequences to integer sequences
    seq_int_list = []
    for seq in user_inputs:
        seq_int = [dna2int.get(char, dna2int["N"]) for char in seq]  # Default to "N" for ambiguous characters
        seq_int_list.append(torch.tensor(seq_int, dtype=torch.long))

    # Pad sequences to the length of the longest sequence in the batch
    padded_sequences = pad_sequence(seq_int_list, batch_first=True, padding_value=dna2int["pad"])

    return padded_sequences


def predict_cpg_counts_arbitrary_length(model, user_inputs: list[str]) -> list[float]:
    """
    Predict CpG counts for a batch of DNA sequences of arbitrary lengths.
    """
    model.eval()
    with torch.no_grad():
        # Preprocess the input sequences
        input_tensor = preprocess_arbitrary_length_inputs(user_inputs)

        # Make predictions
        predictions = model(input_tensor).squeeze(1)  # Adjust shape if necessary
    return predictions.tolist()

# Example Usage
while True:
    user_input = input("Enter DNA sequences separated by commas (or type 'exit' to quit): ").strip().upper()

    # Exit condition
    if user_input == "EXIT":
        print("Exiting...")
        break

    # Split input into individual sequences
    user_sequences = [seq.strip() for seq in user_input.split(",")]

    # Validate input
    if not all(seq and all(char in dna2int for char in seq) for seq in user_sequences):
        print("Invalid DNA sequences detected. Please enter sequences containing only 'N', 'A', 'C', 'G', 'T'.")
        continue

    # Predict CpG counts
    try:
        cpg_counts = predict_cpg_counts_arbitrary_length(model, user_sequences)
        for seq, count in zip(user_sequences, cpg_counts):
            print(f"Sequence: {seq}, Predicted CpG count: {count:.2f}")
    except Exception as e:
        print(f"Error during prediction: {e}")